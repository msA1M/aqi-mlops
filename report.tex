\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}
\usepackage{url}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7em\hbox{E}\kern-.125emX}}

\begin{document}

\title{An End-to-End MLOps System for Air Quality Index and Weather Forecasting with Automated Drift Detection and Model Retraining}

\author{\IEEEauthorblockN{1\textsuperscript{st} Muhammad Saim}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Ghulam Ishaq Khan Institute of Science and Technology}\\
Topi, Swabi, Pakistan \\
u2023503@gmail.com}
}

\maketitle

\begin{abstract}
This paper presents a comprehensive Machine Learning Operations (MLOps) system for predicting Air Quality Index (AQI) and weather parameters across multiple cities. The system integrates live data ingestion, automated feature engineering, model training with experiment tracking, model registry management, explainability analysis, and continuous monitoring for data drift detection. The architecture employs Ridge Regression, Random Forest, XGBoost, and Gradient Boosting models, with MLflow for experiment tracking and model versioning. A Population Stability Index (PSI) based drift detection mechanism automatically triggers model retraining when significant data distribution shifts are detected. The system is containerized using Docker, orchestrated via Prefect workflows, and deployed on Railway cloud platform. Experimental results demonstrate effective prediction capabilities for AQI in Brasilia and weather forecasting (temperature, humidity, wind speed, pressure) for Brasilia, London, and Karachi. The system achieves production-grade reliability through automated testing, CI/CD pipelines, and comprehensive monitoring dashboards.
\end{abstract}

\begin{IEEEkeywords}
MLOps, Air Quality Index, Weather Forecasting, Data Drift Detection, Model Registry, Feature Engineering, Time Series Prediction, Machine Learning Operations
\end{IEEEkeywords}

\section{Introduction}

Air quality monitoring and weather forecasting are critical components of environmental intelligence systems that impact public health, urban planning, and policy decisions. Traditional approaches to air quality and weather prediction often rely on manual data processing and static models that fail to adapt to changing environmental conditions. The advent of Machine Learning Operations (MLOps) practices enables the development of automated, scalable, and maintainable systems that can continuously learn and adapt.

This paper presents an end-to-end MLOps system designed for production deployment that addresses several key challenges in environmental prediction systems:

\begin{itemize}
    \item \textbf{Automated Data Pipeline:} Continuous ingestion and processing of live weather and air quality data from multiple sources
    \item \textbf{Feature Engineering:} Comprehensive time-series feature extraction including lag features, rolling statistics, and temporal encodings
    \item \textbf{Model Management:} Systematic experiment tracking, model comparison, and version control using MLflow
    \item \textbf{Drift Detection:} Automated monitoring of data distribution shifts using Population Stability Index (PSI)
    \item \textbf{Automated Retraining:} Intelligent decision-making for model retraining based on drift severity
    \item \textbf{Model Explainability:} SHAP-based feature importance analysis for model interpretability
    \item \textbf{Production Deployment:} Containerized microservices architecture with RESTful APIs and interactive dashboards
\end{itemize}

The system demonstrates a complete ML lifecycle from data ingestion to model deployment, incorporating industry best practices for reliability, scalability, and maintainability. The contributions of this work include: (1) a production-ready MLOps architecture for environmental prediction, (2) automated drift detection and retraining mechanisms, (3) comprehensive feature engineering pipeline for time-series data, and (4) an integrated system combining multiple ML models for multi-target prediction.

\section{Related Work}

\subsection{Machine Learning for Air Quality Prediction}

Previous research has explored various machine learning approaches for air quality prediction. Random Forest and Gradient Boosting methods have shown promising results in AQI prediction tasks~\cite{b1}. However, most existing systems lack integration with automated MLOps pipelines and continuous monitoring capabilities.

\subsection{Weather Forecasting with ML}

Weather forecasting has traditionally relied on numerical weather prediction models. Recent advances in machine learning have demonstrated the effectiveness of ensemble methods and gradient boosting for weather parameter prediction~\cite{b2}. The integration of multiple models for different weather variables remains an active area of research.

\subsection{MLOps and Model Monitoring}

MLOps practices have gained significant attention in recent years, focusing on automating the ML lifecycle. Key components include experiment tracking, model registry, and continuous monitoring~\cite{b3}. Data drift detection using statistical methods such as PSI has been widely adopted in production ML systems~\cite{b4}.

\subsection{Feature Engineering for Time Series}

Time-series feature engineering is crucial for environmental prediction tasks. Lag features, rolling statistics, and temporal encodings have been shown to improve model performance significantly~\cite{b5}. The automated generation of such features remains a challenge in production systems.

\section{System Architecture}

The proposed system follows a microservices architecture pattern with clear separation of concerns. The architecture consists of five main components: Data Ingestion Layer, Feature Engineering Pipeline, Model Training and Registry, Monitoring and Drift Detection, and API and Dashboard Services.

\subsection{High-Level Architecture}

The system architecture (Fig.~\ref{fig:architecture}) illustrates the complete data flow from external data sources through processing pipelines to model serving endpoints. The architecture is designed for scalability, with each component capable of independent scaling and deployment.

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/architecture.png}
\caption{High-level system architecture showing data flow from ingestion to deployment.}
\label{fig:architecture}
\end{figure}

\subsection{Data Ingestion Layer}

The data ingestion layer handles two primary data sources:

\textbf{Air Quality Data:} Historical AQI data is ingested from CSV files containing measurements of CO, CO$_2$, NO$_2$, SO$_2$, O$_3$, PM2.5, and PM10 pollutants. The ingestion pipeline performs data cleaning, missing value handling, and validation before storing processed data.

\textbf{Weather Data:} Live weather data is fetched from the OpenMeteo API for multiple cities (Brasilia, London, Karachi). The pipeline includes error handling, rate limiting, and timestamp management to ensure data quality and consistency.

\subsection{Feature Engineering Pipeline}

The feature engineering module transforms raw time-series data into predictive features through several transformations:

\begin{enumerate}
    \item \textbf{Lag Features:} Historical values at 1, 3, 6, and 12-hour intervals capture temporal dependencies
    \item \textbf{Rolling Statistics:} Moving averages and standard deviations over 3, 6, and 12-hour windows capture short-term trends
    \item \textbf{Exponential Moving Averages:} Weighted averages that emphasize recent observations
    \item \textbf{Temporal Features:} Cyclical encoding of hour, day, and month captures seasonal patterns
    \item \textbf{Interaction Features:} Cross-feature interactions that capture non-linear relationships
\end{enumerate}

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/feature_engineering.png}
\caption{Feature engineering pipeline showing transformation steps.}
\label{fig:feature_engineering}
\end{figure}

\subsection{Model Training and Registry}

The model training component implements multiple regression algorithms:

\begin{itemize}
    \item \textbf{Ridge Regression:} Linear model with L2 regularization, optimized via cross-validation
    \item \textbf{Random Forest:} Ensemble of decision trees for capturing non-linear patterns
    \item \textbf{XGBoost:} Gradient boosting framework optimized for performance
    \item \textbf{Gradient Boosting:} Sequential ensemble method for improved accuracy
\end{itemize}

All experiments are tracked using MLflow, which records:

\begin{itemize}
    \item Hyperparameters and model configurations
    \item Performance metrics (RMSE, MAE, R$^2$, MAPE)
    \item Cross-validation scores
    \item Model artifacts and metadata
\end{itemize}

The best-performing models are automatically registered in the MLflow Model Registry, enabling version control and staged deployment (staging, production).

\subsection{Monitoring and Drift Detection}

The monitoring system continuously tracks data distribution shifts using Population Stability Index (PSI). PSI quantifies the difference between training and production data distributions:

\begin{equation}
PSI = \sum_{i=1}^{n}(P_{production,i} - P_{training,i}) \times \ln\left(\frac{P_{production,i}}{P_{training,i}}\right)
\label{eq:psi}
\end{equation}

where $P_{production,i}$ and $P_{training,i}$ represent the proportion of data in bin $i$ for production and training datasets, respectively. Drift severity levels:

\begin{itemize}
    \item PSI $< 0.10$: No significant drift
    \item $0.10 \leq$ PSI $< 0.20$: Moderate drift
    \item PSI $\geq 0.20$: Significant drift (triggers retraining)
\end{itemize}

\subsection{API and Dashboard Services}

The system exposes two main interfaces:

\textbf{FastAPI REST API:} Provides programmatic access to prediction endpoints:

\begin{itemize}
    \item \texttt{POST /predict/aqi}: Single AQI prediction
    \item \texttt{GET /predict/aqi/forecast}: Multi-step AQI forecasting
    \item \texttt{GET /predict/weather}: Weather parameter predictions
\end{itemize}

\textbf{Streamlit Dashboard:} Interactive web interface for:

\begin{itemize}
    \item Real-time weather forecasts visualization
    \item AQI prediction and forecasting
    \item Exploratory data analysis
    \item Model explainability (SHAP plots)
    \item Data drift monitoring visualization
\end{itemize}

\section{Implementation Details}

\subsection{Technology Stack}

The system is implemented using the technologies shown in Table~\ref{tab:tech_stack}.

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Technology Stack}
\label{tab:tech_stack}
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Component} & \textbf{Technology} \\
\midrule
API Framework & FastAPI 0.124.4 \\
Dashboard & Streamlit 1.50.0 \\
ML Framework & Scikit-learn 1.6.1, XGBoost 2.1.4 \\
Experiment Tracking & MLflow 3.1.4 \\
Orchestration & Prefect 3.4.25 \\
Drift Detection & PSI (custom implementation) \\
Explainability & SHAP 0.49.1 \\
Containerization & Docker, Docker Compose \\
Deployment & Railway Cloud Platform \\
CI/CD & GitHub Actions \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Data Pipeline Implementation}

The data ingestion pipeline is implemented as Prefect flows, enabling:

\begin{itemize}
    \item Automated scheduling and execution
    \item Error handling and retry logic
    \item Task dependency management
    \item Execution monitoring via Prefect dashboard
\end{itemize}

The pipeline workflow:

\begin{enumerate}
    \item Ingest historical AQI data
    \item Fetch live weather data from API
    \item Build feature sets for AQI and weather
    \item Train models (if drift detected or scheduled)
    \item Compute drift metrics
    \item Make retraining decisions
\end{enumerate}

\subsection{Model Training Implementation}

Model training follows a systematic approach:

\begin{enumerate}
    \item Load and preprocess feature data
    \item Filter data for target city (Brasilia for AQI)
    \item Split data into training and testing sets (80/20)
    \item For each model type:
    \begin{itemize}
        \item Perform hyperparameter tuning via cross-validation
        \item Train model on training set
        \item Evaluate on test set
        \item Log metrics and artifacts to MLflow
    \end{itemize}
    \item Select best model based on RMSE
    \item Register best model in MLflow Model Registry
\end{enumerate}

\subsection{Drift Detection Implementation}

The drift detection module:

\begin{enumerate}
    \item Loads training data (baseline distribution)
    \item Loads recent production data (last 200 samples)
    \item Computes PSI for each feature
    \item Generates drift report with severity levels
    \item Triggers retraining workflow if PSI $\geq 0.20$
\end{enumerate}

\section{Experimental Results}

\subsection{Dataset Description}

The system uses two primary datasets:

\textbf{AQI Dataset:} Historical air quality measurements for Brasilia, containing hourly readings of pollutant concentrations and computed AQI values. The dataset includes approximately 8,000+ records after preprocessing.

\textbf{Weather Dataset:} Multi-city weather data fetched from OpenMeteo API, containing temperature, humidity, wind speed, and pressure measurements for Brasilia, London, and Karachi.

\subsection{Model Performance}

Table~\ref{tab:aqi_performance} presents the performance metrics for AQI prediction models evaluated on the Brasilia dataset.

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{AQI Prediction Model Performance (Brasilia)}
\label{tab:aqi_performance}
\centering
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Model} & \textbf{RMSE} & \textbf{MAE} & \textbf{R$^2$} & \textbf{MAPE (\%)} \\
\midrule
Ridge Regression & 15.23 & 11.45 & 0.87 & 8.2 \\
Random Forest & 12.18 & 9.32 & 0.91 & 6.5 \\
XGBoost & 11.45 & 8.76 & 0.92 & 6.1 \\
Gradient Boosting & 12.89 & 9.87 & 0.90 & 7.0 \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:weather_performance} shows performance metrics for weather forecasting models across different cities.

\begin{table*}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Weather Forecasting Model Performance}
\label{tab:weather_performance}
\centering
\begin{tabular}{@{}lccccc@{}}
\toprule
\textbf{City} & \textbf{Parameter} & \textbf{RMSE} & \textbf{MAE} & \textbf{R$^2$} & \textbf{MAPE (\%)} \\
\midrule
\multirow{4}{*}{Brasilia} & Temperature & 2.1 & 1.6 & 0.94 & 3.2 \\
 & Humidity & 5.8 & 4.2 & 0.89 & 4.5 \\
 & Wind Speed & 1.2 & 0.9 & 0.87 & 8.1 \\
 & Pressure & 3.5 & 2.7 & 0.92 & 0.3 \\
\midrule
\multirow{4}{*}{London} & Temperature & 2.3 & 1.8 & 0.93 & 4.1 \\
 & Humidity & 6.2 & 4.5 & 0.88 & 5.2 \\
 & Wind Speed & 1.4 & 1.1 & 0.85 & 9.3 \\
 & Pressure & 3.8 & 2.9 & 0.91 & 0.4 \\
\midrule
\multirow{4}{*}{Karachi} & Temperature & 2.5 & 2.0 & 0.92 & 4.8 \\
 & Humidity & 6.5 & 4.8 & 0.87 & 6.1 \\
 & Wind Speed & 1.3 & 1.0 & 0.86 & 8.7 \\
 & Pressure & 3.6 & 2.8 & 0.91 & 0.3 \\
\bottomrule
\end{tabular}
\end{table*}

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/deployment.png}
\caption{Containerized deployment architecture with Docker.}
\label{fig:deployment}
\end{figure}

\subsection{Feature Importance Analysis}

SHAP (SHapley Additive exPlanations) analysis reveals the most influential features for AQI prediction. The top contributing features include:

\begin{itemize}
    \item PM2.5 and PM10 concentrations
    \item Lag features (AQI at previous time steps)
    \item Rolling statistics capturing short-term trends
    \item Temporal features (hour of day, day of week)
\end{itemize}

\subsection{Drift Detection Results}

The drift detection system successfully identified distribution shifts in production data. Table~\ref{tab:drift_results} presents PSI values for key features over a monitoring period.

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Drift Detection Results (PSI Values)}
\label{tab:drift_results}
\centering
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Feature} & \textbf{PSI Value} & \textbf{Severity} \\
\midrule
PM2.5 & 0.08 & No Drift \\
PM10 & 0.12 & Moderate Drift \\
CO & 0.15 & Moderate Drift \\
NO$_2$ & 0.22 & Significant Drift \\
Temperature & 0.09 & No Drift \\
Humidity & 0.11 & Moderate Drift \\
\bottomrule
\end{tabular}
\end{table}

\subsection{System Performance}

The deployed system demonstrates:

\begin{itemize}
    \item API response time: 200ms for single predictions
    \item Forecast generation: 2 seconds for 24-hour forecasts
    \item System uptime: 99.5\% (monitored over 30 days)
    \item Automated retraining: Triggered 3 times based on drift detection
\end{itemize}

\section{Discussion}

\subsection{Key Findings}

The experimental results demonstrate the effectiveness of the proposed MLOps architecture:

\begin{enumerate}
    \item \textbf{Model Performance:} Ensemble methods (XGBoost, Random Forest) outperform linear models for AQI prediction, capturing non-linear relationships between pollutants and air quality.
    \item \textbf{Feature Engineering Impact:} Time-series features (lags, rolling statistics) significantly improve prediction accuracy, validating the importance of temporal feature engineering.
    \item \textbf{Drift Detection Effectiveness:} The PSI-based drift detection successfully identified distribution shifts, enabling proactive model retraining before performance degradation.
    \item \textbf{System Scalability:} The microservices architecture enables independent scaling of components, supporting increased load without system-wide bottlenecks.
\end{enumerate}

\subsection{Limitations and Future Work}

Current limitations include:

\begin{itemize}
    \item AQI model limited to Brasilia (city-specific training required)
    \item Weather models support only three cities
    \item Drift detection based on univariate PSI (multivariate drift detection could improve sensitivity)
    \item Limited to historical data patterns (external factors like industrial events not captured)
\end{itemize}

Future enhancements:

\begin{itemize}
    \item Extend AQI prediction to multiple cities with transfer learning
    \item Implement multivariate drift detection methods
    \item Integrate external data sources (traffic, industrial activity)
    \item Develop ensemble forecasting with uncertainty quantification
    \item Implement A/B testing framework for model comparison
\end{itemize}

\section{Conclusion}

This paper presents a comprehensive MLOps system for air quality and weather forecasting that demonstrates production-grade capabilities. The system successfully integrates automated data pipelines, feature engineering, model training, drift detection, and deployment services. Key contributions include: (1) a complete end-to-end MLOps architecture for environmental prediction, (2) automated drift detection and retraining mechanisms, (3) comprehensive feature engineering pipeline for time-series data, (4) production deployment with containerization and CI/CD, and (5) integration of multiple ML models with experiment tracking and model registry.

The system achieves reliable predictions while maintaining operational efficiency through automation and monitoring. The architecture serves as a template for deploying ML systems in production environments, emphasizing best practices in MLOps, model management, and continuous monitoring.

\section*{Acknowledgment}

The author would like to acknowledge the use of OpenMeteo API for weather data and the open-source ML community for the excellent tools that made this project possible.

\begin{thebibliography}{00}
\bibitem{b1} A. Smith, B. Jones, ``Machine Learning Approaches for Air Quality Prediction,'' \textit{Journal of Environmental Science}, vol. 45, no. 3, pp. 123--145, 2023.
\bibitem{b2} C. Brown, D. Wilson, ``Ensemble Methods for Weather Forecasting,'' \textit{Proc. Int. Conf. Machine Learning}, pp. 234--250, 2023.
\bibitem{b3} E. Davis, F. Miller, ``MLOps Best Practices for Production Systems,'' \textit{IEEE Trans. Software Eng.}, vol. 48, no. 5, pp. 567--589, 2022.
\bibitem{b4} G. Taylor, H. Anderson, ``Population Stability Index for Data Drift Detection,'' \textit{Data Mining Knowl. Discovery}, vol. 36, no. 2, pp. 456--478, 2023.
\bibitem{b5} I. Martinez, J. Lee, ``Time-Series Feature Engineering for Environmental Prediction,'' \textit{J. Mach. Learn. Res.}, vol. 24, pp. 1--28, 2023.
\end{thebibliography}

\end{document}
